
<!DOCTYPE html>

<html>

<head>
   <style>
      td, th {
        border: 0px solid black;          
        }
      img{
   padding: 5px;
}
      </style>

  <title>Mask-free OVIS</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">
  
  <link rel="shortcut icon" href="./static/images/ovis/jhu_web.png" />

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">
  <link rel="stylesheet" href="https://unpkg.com/image-compare-viewer/dist/image-compare-viewer.min.css">
  <link rel="stylesheet" href="css/app.css">
    <link rel="stylesheet" href="css/bootstrap.min.css">

<script src="https://unpkg.com/image-compare-viewer/dist/image-compare-viewer.min.js"></script>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

</head>

<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title"> Mask-free OVIS: Open-Vocabulary Instance Segmentation without Manual Mask Annotations</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://vibashan.github.io/">Vibashan VS</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://ningyu1991.github.io/">Ning Yu</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=tAUdLM0AAAAJ&hl=en">Chen Xing</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://canqin.tech/">Can Qin</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://fly6464.github.io/">Mingfei Gao</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="http://www.niebles.net/">Juan Carlos Niebles</a><sup>2</sup>,
            </span>
            <span class="author-block"></span>
              <a href="https://engineering.jhu.edu/vpatel36/sciencex_teams/vishalpatel/">Vishal M. Patel,</a><sup>1</sup>
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=sgBB2sUAAAAJ&hl=en">Ran Xu</a><sup>2</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Johns Hopkins University<sup>1</sup>,</span>
            <span class="author-block">Northeastern University<sup>3</sup>,</span>
            <span class="author-block">Salesforce Research<sup>2</sup></span>
          </div>
         
         <div class="column has-text-centered">
            <a href="as">CVPR 2023</a>
            </span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
<!--               <span class="link-block">
                <a href="https://drive.google.com/file/d/1j9-1oOzh89T6_wy-aAXBriLNlvh80D60/view?usp=sharing"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Supplementary material</span>
                </a>
              </span> -->
              <span class="link-block">
                <a href="https://github.com/Vibashan/Labelfree-OVIS"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <!--  <i class="ai ai-arxiv"></i> -->
<!--                      <i class="fab fa-github"></i> -->
                     <svg class="svg-inline--fa fa-github fa-w-16" aria-hidden="true" focusable="false" data-prefix="fab" data-icon="github" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" data-fa-i2svg=""><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg>
                  </span>
                  <span>Github</span>
                </a>
              </span>
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>Colab (Coming Soon)</span>
                </a>
              </span>
            </div>
          </div>

        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        
        <h2 class="title is-3">Overview</h2>
        <img src="./static/images/ovis/ovis-gif5.gif" alt="" border=0 height=600 width=1500></img>
        <div class="content has-text-justified">
          <ul>
            <li> Our work proposes a manual-mask-free approach for open-vocabulary instance segmentation leveraging a pre-trained vision-language model. </li>
            <li> Specifically, we generate pseudo-masks annotations for objects of interest from image-caption pairs using pre-trained VLM and weakly-supervised proposal and segmentation network. </li>
            <li> These generated pseduo-mask annotations are then used to train an instance segmentation model, completely eliminating the need for human-provided box-level or pixel-level annotations. </li>

          </ul>
          
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Pseduo-mask Generation Framework</h2>
          <div class="content has-text-justified">
            <h5 class="subtitle has-text-centered"></h5> 

          <center>Overview of the proposed framework</center>
            <img src="./static/images/ovis/Archi_v2.svg" alt="" border=0 height=500 width=1500></img></
          <p>
            Given an image-caption pair, we generate a GradCAM activation for the object of interest, leveraging the localization capability of a pre-trained vision-language model (in this case "umbrella").
             To further refine the activation map, we perform an iterative masking strategy. Then, using the activation map as a guidance function, we choose the best proposals that cover the object from a 
             weakly-supervised proposal network (WSPN) and generate box-level annotations. Next, we crop the image based on the generated pseudo-bounding box and perform weakly-supervised segmentation to obtain 
             pixel-level annotations. Overall, given an image-caption pair, our pipeline generates pseudo-mask annotations by leveraging the pre-trained vision-language and weakly supervised models. 
             Finally, the generated pseudo-mask annotations are used to train an instance segmentation model, eliminating the need for human-provided box-level or pixel-level annotations.
          </p> 

      
          </div>
       </div>
      </div>
    </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Pseduo-mask visualizations</h2>
          <div class="content has-text-justified">
            <h5 class="subtitle has-text-centered"></h5> 
            <img src="./static/images/ovis/qual_vis.png" alt="" border=0 height=500 width=1500></img></
          <p>
            (A) Visualization of activation maps generated to cover the object of interest (woman and dog), which were used to select the best bounding box proposal.
            (B) Visualization of generated pseudo-mask annotations generated using our pipeline.
          </p> 

      
          </div>
       </div>
      </div>
    </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Mask-rcnn predicition visualizations</h2>
          <div class="content has-text-justified">
            <h5 class="subtitle has-text-centered"></h5> 
            <img src="./static/images/ovis/pred-vis.svg" alt="" border=0 height=500 width=1500></img></
          <p>
            The top and bottom rows of the visualization display the predictions generated by the Mask-RCNN model, which was trained on pseudo-masks created from two datasets: COCO and Open Images, repectively.
            By training on a large number of pseudo-masks, the Mask-RCNN model is able to filter out any noise present in the masks, leading to improved predictions that include complete masks and tight bounding boxes.
          </p> 

      
          </div>
       </div>
      </div>
    </div>
</section>


<section class="section" id="BibTeX">
  <div class="container content is-max-desktop">
    <h2 class="title">BibTeX</h2>
    <pre><code>
  @article{vs2023mask,
     title={Mask-free OVIS: Open-Vocabulary Instance Segmentation without Manual Mask Annotations},
     author={VS, Vibashan and Yu, Ning and Xing, Chen and Qin, Can and Gao, Mingfei and Niebles, Juan Carlos and Patel, Vishal M and Xu, Ran},
     journal={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
     year={2023}
   }</code></pre>
  </div>
</section>

<section class="section" >
  <div class="container is-max-desktop content">
    <h5 class="title"> Acknowledgement: The website Template taken from <span class="author-block">
              <a href="https://nerfies.github.io/" target="_blank">Nerfies</a></h5>

  </div>
</section>

<script>
    const viewers = document.querySelectorAll(".image-compare");
    viewers.forEach((element) => {
        let view = new ImageCompare(element, {
            hoverStart: true,
            addCircle: true
        }).mount();
    });

    $(document).ready(function () {
        var editor = CodeMirror.fromTextArea(document.getElementById("bibtex"), {
            lineNumbers: false,
            lineWrapping: true,
            readOnly: true
        });
        $(function () {
            $('[data-toggle="tooltip"]').tooltip()
        })
    });
</script>
</body>
</html>
